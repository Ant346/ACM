{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc550bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell and reassure you're using python 3.9. Swich to 3.9 otherwise using \"Command palette\" in the right bottom corner of Colab.\n",
    "!python --version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5e6d712",
   "metadata": {},
   "source": [
    "# EXECUTE THE CELL BELOW ONLY IF YOU'RE WORKING IN GOOGLE COLAB! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b09096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the cell only ONCE\n",
    "\n",
    "!git clone https://gitflic.ru/project/aidynamicaction/classedu2023-advctrl.git\n",
    "%cd /content/classedu2023-advctrl/assignments/asgn-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "320d66ac",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#333333; text-align:center; line-height: 0;\"> <img style=\"right;\" src=\"logo.png\" width=18% height=18%> Advanced Control Methods | Assignment 4 \n",
    "</h1>\n",
    "<br/><br/>\n",
    "\n",
    "**First, familiarize yourself with [Rcognita](https://github.com/AIDynamicAction/rcognita) if you have not already done so. This assignment is based on this framework, so it's better to have an intuition about what's going on behind the scenes.**\n",
    "\n",
    "The goal of this assignment is to implement a classic **MPC** controller, described in the section 1.2, namely, `_actor_cost` and `_actor_optimizer` methods.\n",
    "\n",
    "___Total points:___ 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8752ad66",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 1: Introduction to model predictive control (MPC) </h2>\n",
    "\n",
    "***\n",
    "###  <font color=\"blue\"> 1.1 Intuition behind MPC </font>\n",
    "**MPC** is one of the most popular methods of obtaining the optimal controller and, in fact, is an industry standard.\n",
    "Let us start from the most reasonable question. Why should we care about **MPC**? Why do we even need that thing? Are there any problems that naturally lead to the development of such a model?\n",
    "\n",
    "In fact, yes. There are infinitely many applications of **MPC**, including petroleum extraction, agricultural facilities, automatic assembly and so on. But let us take a look at the development of such a type of machines that are impressive not only to an expert in the field - humanoid robots. If you've ever seen a video of Boston Dynamics' humanoid robots, you've probably wondered, how do the engineers made it work? How does such a complex machine make those precise movements so that it is capable of performing acrobatics that already exceeds the abilities of a typical human in some aspects (i.e. backflip)?\n",
    "\n",
    "The answer is, you guessed it, **MPC**. \n",
    "\n",
    "The performance of the modern robots comes with its cost. The problem of generating control for any robot requires:\n",
    "\n",
    "- real time performance, as there are in general almost no stable states in the robot's movement, and all the calculations should be performed quickly\n",
    "- optimizing a complex composite cost to a certain time horizon in order to follow the high-level plan\n",
    "- (in some cases) discrete-continuous optimization, which is difficult\n",
    "- taking into account various types of constraints, i.e.\n",
    "    1. torque and angle limits for the servomotors (in a form of inequality)\n",
    "    2. functional constraints following from the problem statement, that do not always allow for an analytical solution \n",
    "    3. also there could be constraints on foot placement, body placement, slippery surfaces, etc.\n",
    "    4. constraints of the limbs non-intersection (if this is a case)\n",
    "\n",
    "All in all, such a problem could lack a closed form solution, like $\\boldsymbol u = \\boldsymbol f(\\text{state}, \\text{target})$.\n",
    "\n",
    "One of the most fundamental important ways to obtain an optimal controller is __MPC__. \n",
    "\n",
    "* __MPC-like algorithms__ are ones of the few that can handle very complex constraints, including functional, nonlinear, nonconvex, etc.\n",
    "\n",
    "Informally speaking, algorithms that generate control for a complex dynamical system typically have to be predictive. And taking the system model into account helps along the way. In order to optimize an objective along the trajectory, we could try to estimate the system behaviour in the future. This is litearlly what **MPC** does. With that in hand, let us state the problem and the **MPC** more formally.\n",
    "\n",
    "###  <font color=\"blue\"> 1.2 MPC mathematical description </font>\n",
    "<a id='2.2'></a>\n",
    "\n",
    "First of all, we consider a controlled physical system described by the system of ordinary differential equations \n",
    "<a id='System'></a>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "\\dot{\\boldsymbol x} = \\boldsymbol f(\\boldsymbol x, \\boldsymbol u)\\\\\n",
    "\\boldsymbol y = h(\\boldsymbol x) \\\\\n",
    "\\boldsymbol x(0)=\\boldsymbol x_{0}\\\\\n",
    "\\end{cases}\n",
    "\\end{equation}$$ \n",
    "where $x_{0}$ is the **initial state**.In the following table we introduce some basic notation. From now on, we will write vectors in **bold**.\n",
    "<a id='Notation'></a>\n",
    "\n",
    "| Notation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| Description |\n",
    "|:-----------------------:|-------------|\n",
    "| $\\boldsymbol f(\\cdot, \\cdot) : \\mathbb{R}^{n} \\times \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$ |A **state dynamic function** or, more informally, **righ-hand-side** of a system <br /> of ordinary differential equations $\\dot{\\boldsymbol x} = \\boldsymbol f(\\boldsymbol x, \\boldsymbol u)$|\n",
    "| $\\boldsymbol x \\in \\mathbb{R}^{n} $ | An element of the **state space** of a controlled system of dimensionality $n$ |\n",
    "| $\\boldsymbol u \\in \\mathbb{R}^{m}$ | An element of the **action space** of a controlled system of dimensionality $m$ |\n",
    "| $\\boldsymbol y \\in \\mathbb{R}^{k}$ | An **observartion**|\n",
    "| $\\mathbb{X}\\subset \\mathbb{R}^{n} $| **State constraint set**|\n",
    "| $\\mathbb{U}\\subset \\mathbb{R}^{m} $| **Action constraint set**|\n",
    "| $\\boldsymbol h(\\cdot): \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{k}$ | **Observation function**  |\n",
    "| $\\kappa(\\cdot) : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{n}$ | **Policy** function |\n",
    "| $\\rho(\\cdot) : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ | **Stage cost** function  |\n",
    "| $J_N(\\cdot, \\cdot): \\mathbb{R}^n \\times \\mathcal{K} \\rightarrow \\mathbb{R}$| **N-step cost** (might be refered as **actor cost** either), <br /> where $\\mathcal{K}$ is some functional space of admissible policies |\n",
    "| $\\delta$ | **Sampling time** |\n",
    "| $\\boldsymbol x_k$   | A **state** at time $k\\delta$: $\\qquad\\boldsymbol x (k \\delta)$   |\n",
    "\n",
    "Here we would like to make a few clarifications on the notation introduced.\n",
    "* For **MPC** N-step cost has the following form  $J_N(\\boldsymbol x_{k}, \\kappa(\\cdot)):=\\int_{k\\delta}^{(k+N)\\delta}\\rho(\\boldsymbol x(t), \\kappa(\\boldsymbol x(t))) dt$\n",
    "* In the following problems we consider $\\mathbb{X} = \\mathbb{R}^{n}$ without any remarks but in general we might want to introduce some reasonable **state constraint set**.\n",
    "* When working with the system, we cannot know the exact value of the characteristics we are interested in. What we do is **make a measurement** calculatung **observation function** $\\boldsymbol h(\\cdot)$. The result we call an **observation** $\\boldsymbol y$. For now we consider $\\boldsymbol y = \\boldsymbol h(\\boldsymbol x) := \\boldsymbol x$ further but in general it might not be so! For example, if we control a body motion on a plane $(x,y)$, we could measure a distance to the origin: $\\boldsymbol h(\\boldsymbol x) = \\lVert \\boldsymbol x \\rVert$. \n",
    "* Most modern controllers are digital, therefore the control signal is generated by sampling with some **sampling time** $\\delta$. In that case we call it **digital control setting**. The following table gives a comparison between mathematical description of the original setting of the controlled system and its **digital control setting**.\n",
    "<a id='Comparison_table'></a>\n",
    "\n",
    "|Original setting|Digital control setting|\n",
    "|:-----------------------|:--------------------------|\n",
    "|1) $ \\qquad \\dot{\\boldsymbol x}=\\boldsymbol f\\left(\\boldsymbol x, \\boldsymbol u\\right) $ | $\\text{1*)} \\quad \\dot{\\boldsymbol x}=\\boldsymbol f\\left(\\boldsymbol x, \\boldsymbol u^{\\delta}\\right)$|\n",
    "| $\\text{2)} \\quad \\boldsymbol u=\\boldsymbol u(t), t \\in[0, T]$  | $\\text{2*)} \\quad \\boldsymbol u_k(t)=\\boldsymbol u(k\\delta) , t \\in[k \\delta,(k+1) \\delta]$  | \n",
    "| $$\\text{3)} \\quad \\boldsymbol x(t):=\\boldsymbol x_{t_0}+\\int_{t_0}^{t}f\\left(\\boldsymbol x(\\tau), \\boldsymbol u(\\tau) \\right) d \\tau$$| $$\\text{3*)} \\quad \\boldsymbol x^{\\boldsymbol u_{k}}(t):=\\boldsymbol x_{k}+\\int_{k \\delta}^{t}f\\left(\\boldsymbol x(\\tau), \\boldsymbol u_{k}\\right) d \\tau$$|     \n",
    "\n",
    "<!--- $$\\boldsymbol x_{i \\mid k}:=\\boldsymbol x((k+i-1) \\delta), k \\in \\mathbb{N}$$\n",
    "$\\boldsymbol u^{\\delta}(t) \\equiv \\boldsymbol u_{i \\mid k}=\\kappa\\left(\\boldsymbol x_{i \\mid k}\\right), t \\in[k \\delta,(k+i) \\delta]$ \n",
    "One can see that for any $k \\in \\mathbb{N}$, the state $x^{u_{k}}(t)$ at $t \\geq k \\delta$ under $u_{k}$ satisfies\n",
    "-->\n",
    "<p style=\"text-align: center;\">\n",
    "\n",
    "</p>\n",
    "\n",
    "From now and on by the system we mean a system in the **digital control setting**, which is illustrated on the figure below .\n",
    "<img src=\"digital_control_setting.svg\" width=40% height=40% />\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In general, our optimal control problem is written as $\\min_{\\kappa(\\cdot)}\\int_{k\\delta}^{(k+N)\\delta}\\rho(\\boldsymbol x(t), \\kappa(\\boldsymbol x(t))) dt$, where $N$ is **prediction horizon**. But in **MPC** we switch to a discrete sum instead of an integral: $$\\min _{\\boldsymbol u_{k + i}: i=0, \\ldots, N-1} \\left(\\sum_{i=1}^{N-1} \\rho \\left(\\hat{\\boldsymbol x}_{k + i}, \\boldsymbol u_{k + i}\\right)\\delta \\right) $$ Wich is obviously equivalent to the following form:\n",
    "$$\\min _{ \\boldsymbol u_{k + i}: i=0, \\ldots, N-1} \\left(\\sum_{i=1}^{N-1} \\rho \\left(\\hat{\\boldsymbol x}_{k + i}, \\boldsymbol u_{k + i}\\right)\\right)$$  \n",
    "And now we see that it fits conviniently in our **digital control setting**: we will just find a minimizing sequence of actions for our digital model predictive control for stage costs predicted for N steps forward.  Notice that under digital control our state evolves according to [3*)](#Comparison_table) . Now we need to somehow numerically evaluate the interal $\\int_{k \\delta}^{t}f\\left(\\boldsymbol x(\\tau), \\boldsymbol u_{k}\\right) d \\tau$. In order to do this one might use any numerical integration scheme. For example the **Euler scheme** :\n",
    "<a id='Euler'></a>\n",
    "$$\n",
    "\\boldsymbol x_{k+1}=\\boldsymbol x_{k}+\\delta \\boldsymbol f\\left(\\boldsymbol x_{k}, \\boldsymbol u_{k}\\right) \\text {, }\n",
    "$$\n",
    "#### Algorithm <sup>[1]</sup>:\n",
    "<a id='Objective'></a>\n",
    "Let us describe the **MPC** algorithm for the problem just described above.  \n",
    "At the current state $\\boldsymbol x_{k}$ :\n",
    "\n",
    "(a) **MPC** solves an $N$-step lookahead  problem: $\\min _{\\boldsymbol u_{k + i}: i=0, \\ldots, N-1} \\left(\\sum_{i=0}^{N-1} \\rho \\left(\\hat{\\boldsymbol x}_{k + i}, \\boldsymbol u_{k + i}\\right)\\right)$\n",
    "\n",
    "(b) If $\\left\\{\\boldsymbol u^{*}_{k}, \\ldots, \\boldsymbol u^{*}_{k+N-1}\\right\\}$ is the optimal control sequence of this problem, **MPC** applies $\\boldsymbol u^{*}_{k}$ and discards the other controls $\\boldsymbol u^{*}_{k+1}, \\ldots, \\boldsymbol u^{*}_{k+N-1}$. \n",
    "\n",
    "(c) At the next stage, **MPC** repeats this process, once the next state $\\boldsymbol x_{k}$ is revealed.\n",
    "\n",
    "\n",
    "<img src=\"MPC.svg\" width=35% height=35% />\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0155532e",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#A7BD3F;\"> Section 2: Problems </h2>\n",
    "\n",
    "In the following, for testing, we will use a system representing a three-wheeled robot described by a system of equations\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\dot{x}_c=v \\cos \\alpha \\\\\n",
    "\\dot{y}_c=v \\sin \\alpha \\\\\n",
    "\\dot{\\alpha}=\\omega\n",
    "\\end{cases}\n",
    "$$ where $x_c$ and $y_c$ are coordinates of the center of mass, $v$ and $\\omega$ are velocity of the center of mass and angular velocity respectively and these are components of the control $\\boldsymbol u := (v, \\omega)$ as well.  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rcognita.__utilities import rc, Clock\n",
    "import rcognita.__utilities as utilities\n",
    "from rcognita.systems import System, Sys3WRobotNI\n",
    "from rcognita.controllers import Controller\n",
    "from rcognita.testing_pipeline import create_testing_pipeline\n",
    "from rcognita.visualization import dashboards\n",
    "from rcognita.models import ModelQuadForm\n",
    "import rcognita\n",
    "import numpy as np\n",
    "from matplotlib import rc as rc_params\n",
    "from scipy.optimize import minimize, Bounds\n",
    "rc_params(\"animation\", html=\"jshtml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_action_bounds(method):\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        self.action = method(self, *args, **kwargs)\n",
    "        if hasattr(self, \"action_bounds\") and self.action_bounds != []:\n",
    "            action = np.clip(\n",
    "                self.action, self.action_bounds[:, 0], self.action_bounds[:, 1]\n",
    "            )\n",
    "            self.action = action\n",
    "        return self.action\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77069428",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> 2.1 Problem 1 | Euler predictor </font>\n",
    "Euler predictor uses a simple Euler discretization scheme.\n",
    "\n",
    "It does predictions by increments scaled by a sampling time times the velocity evaluated at each successive node.\n",
    "\n",
    "You already have an experience in implementing such predictor. Now you're intended to wrap this into a corresponding `EulerPredictor` class.\n",
    "\n",
    "* `predict` here is a method that performs only one step: $x_{k+1} = \\delta f(x_k, u_k)$ given some state $x_k$ and action $u_k$\n",
    "* `predict_sequence` performs computations of `predict` method successively and returns `observation_sequence_predicted` of `len = self.prediction_horizon`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EulerPredictor:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pred_step_size: float,\n",
    "        system: System,\n",
    "        dim_input: int,\n",
    "        prediction_horizon: int,\n",
    "    ):\n",
    "        self.system = system\n",
    "        self.pred_step_size = pred_step_size\n",
    "        self.compute_state_dynamics = system.compute_dynamics\n",
    "        self.sys_out = system.out\n",
    "        self.dim_input = dim_input\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "\n",
    "    def predict(self, current_state, action):\n",
    "    \n",
    "        ####################\n",
    "        #YOUR CODE GOES HERE\n",
    "        ####################\n",
    "        next_state = \n",
    "        ####################\n",
    "        #YOUR CODE ENDS HERE\n",
    "        ####################\n",
    "        return next_state\n",
    "\n",
    "    def predict_sequence(self, state, action_sequence):\n",
    "        ####################\n",
    "        #YOUR CODE GOES HERE\n",
    "        ####################\n",
    "\n",
    "        ####################\n",
    "        #YOUR CODE ENDS HERE\n",
    "        ####################\n",
    "        \n",
    "        return observation_sequence_predicted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "512495ac",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> 2.2 Problem 2 | MPC-based Controller implementation </font>\n",
    "Implement MPC-based controller using predictor from the previous task.\n",
    "\n",
    "1. Implement `mpc_objective` that gets an action sequence as decision variable for the main optimization problem $$\\min _{ \\boldsymbol u_{k + i}: i=0, \\ldots, N-1} \\left(\\sum_{i=1}^{N-1} \\rho \\left(\\hat{\\boldsymbol x}_{k + i}, \\boldsymbol u_{k + i}\\right)\\right)$$ \n",
    "2. Implement the mpc algorithm itself in `compute_action` method using scipy optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControllerMPC(Controller):\n",
    "    def __init__(self, predictor, *args, action_bounds=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.predictor = predictor\n",
    "        self.dim_input = self.predictor.system.dim_input\n",
    "        self.dim_output = self.predictor.system.dim_output\n",
    "        self.action_bounds = action_bounds\n",
    "\n",
    "    def compute_action_sampled(self, time, state, observation, observation_target=[]):\n",
    "        \"\"\"\n",
    "        Compute sampled action.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        is_time_for_new_sample = self.clock.check_time(time)\n",
    "\n",
    "        if is_time_for_new_sample:  # New sample\n",
    "            action = self.compute_action(state, observation)\n",
    "            self.times.append(time)\n",
    "            self.action_old = action\n",
    "\n",
    "\n",
    "            return action\n",
    "\n",
    "        else:\n",
    "            return self.action_old\n",
    "\n",
    "\n",
    "    def mpc_objective(\n",
    "        self,\n",
    "        action_sequence, \n",
    "        observation, ## Here state and observation are equivalent\n",
    "    ):\n",
    "        ####################\n",
    "        #YOUR CODE GOES HERE\n",
    "        ####################\n",
    "\n",
    "        ####################\n",
    "        #YOUR CODE ENDS HERE\n",
    "        ####################\n",
    "\n",
    "    @apply_action_bounds\n",
    "    def compute_action(\n",
    "        self, state, observation, time=0 ## Here state and observation are equivalent\n",
    "    ):\n",
    "\n",
    "        ####################\n",
    "        #YOUR CODE GOES HERE\n",
    "        ####################\n",
    "\n",
    "        ####################\n",
    "        #YOUR CODE ENDS HERE\n",
    "        ####################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2672368",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Testing of the implemented controller </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_init = np.array([5, 5, 3 * np.pi / 4])\n",
    "action_init = np.ones(2)\n",
    "prediction_horizon = 5\n",
    "sampling_time=0.01\n",
    "\n",
    "system = Sys3WRobotNI(\n",
    "    dim_input=2,\n",
    "    dim_output=3,\n",
    "    sys_type=\"diff_eqn\",\n",
    "    dim_state=3,\n",
    "    dim_disturb=3,\n",
    "    pars=[]\n",
    ")\n",
    "predictor = EulerPredictor(\n",
    "    pred_step_size=sampling_time,\n",
    "    system=system,\n",
    "    dim_input=system.dim_input,\n",
    "    prediction_horizon=prediction_horizon,\n",
    ")\n",
    "controller = ControllerMPC(\n",
    " action_bounds=np.array([[-25, 25],[-5, 5]]), time_start=0, sampling_time=sampling_time\n",
    ")\n",
    "\n",
    "dashboard = dashboards.RobotTrackingDasboard\n",
    "\n",
    "scenario, animator = create_testing_pipeline(\n",
    "    system, \n",
    "    controller, \n",
    "    state_init=state_init, \n",
    "    action_init=action_init, \n",
    "    model_of_running_objective = ModelQuadForm(weights=np.diag([5, 5, 1, 0, 0])),\n",
    "    observation_namings=[\"x\", \"y\", \"angle\"],\n",
    "    action_namings=[\"lin. speed\", \"ang. speed\"],\n",
    "    system_visualization_dashboard=dashboard,\n",
    "    system_visualization_dashboard_params={\n",
    "        \"time_start\": 0, \n",
    "        \"x_max\": 10, \n",
    "        \"x_min\": -10, \n",
    "        \"y_max\": 10, \n",
    "        \"y_min\": -10\n",
    "        },\n",
    "    time_final=15,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a7f96",
   "metadata": {},
   "source": [
    "### Here you can debug your code. When the code is changed, rerun previous cells to update the scenario cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73452ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.run() # <--- takes some time. (In our case about 30 seconds)\n",
    "trajectory = []\n",
    "for i , (k, v) in enumerate(scenario.cache.items()):\n",
    "    trajectory.append(v[3])\n",
    "\n",
    "trajectory[-30:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45e786c0",
   "metadata": {},
   "source": [
    "### Run the animation to finalize your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "animation = animator.get_animation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daf5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859226f",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    " ***\n",
    " **<sup>[1]</sup> Bertsekas, D. , Reinforcement Learning and Optimal Control**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
